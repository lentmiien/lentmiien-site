extends layout

mixin embeddingGroup(group, opts)
  - const source = group && group.source ? group.source : {};
  - const modeLabel = (opts && opts.modeLabel) || '';
  - const updatedAt = group && (group.latestUpdatedAt || group.latestCreatedAt || group.latestTimestamp);
  - const hasParent = source.parentCollection || source.parentId;
  .border.rounded-3.p-3.mb-3
    .d-flex.justify-content-between.align-items-center.mb-2
      span.fw-semibold= `${opts && opts.index !== undefined ? `#${opts.index + 1} ` : ''}${source.collectionName || 'Unknown source'}`
      .d-flex.flex-wrap.gap-2
        if group && group.similarity !== null && group.similarity !== undefined
          span.badge.text-bg-primary= Number(group.similarity).toFixed(4)
        if modeLabel
          span.badge.text-bg-info= modeLabel
        else if opts && opts.mode
          span.badge.text-bg-info= opts.mode
        if group && group.chunkCount
          span.badge.text-bg-light.text-secondary= `${group.chunkCount} chunk${group.chunkCount === 1 ? '' : 's'}`
        if group && group.models && group.models.length
          span.badge.text-bg-light.text-secondary= group.models.join(', ')
        if opts && opts.topK
          span.badge.text-bg-light.text-secondary= `top ${opts.topK}`
        if group && group.rerank
          span.badge.text-bg-warning.text-dark Reranked
    if group && group.previewText
      p.mb-2= group.previewText.length > 360 ? `${group.previewText.slice(0, 360)}…` : group.previewText
    ul.list-unstyled.small.mb-2
      li
        strong Source:
        |  #{source.collectionName || 'n/a'} · #{source.documentId || 'n/a'}
      if hasParent
        li
          strong Parent:
          |  #{source.parentCollection || 'n/a'} · #{source.parentId || 'n/a'}
      li
        strong Content type:
        |  #{source.contentType || 'n/a'}
      - const isOcrFile = source.collectionName === 'ocr_job_files';
      - const ocrJobId = source.parentId || source.parent_id;
      - const ocrFileId = source.documentId || source.document_id;
      - const isKnowledge = source.collectionName === 'knowledge';
      - const knowledgeId = source.documentId || source.document_id;
      - const isChat = source.collectionName === 'chat_message';
      - const conversationId = source.parentId || source.parent_id;
      - const isASR = source.collectionName === 'asr_jobs';
      - const asrId = source.parentId || source.parent_id;
      - const isImagePrompt = source.collectionName === 'good_images';
      - const imageId = source.documentId || source.document_id;
      if isOcrFile && ocrJobId
        li
          strong OCR job:
          |  
          a(href= ocrFileId ? `/ocr/jobs/${ocrJobId}/view/${ocrFileId}` : `/ocr/jobs/${ocrJobId}/view`, target="_blank", rel="noreferrer") View job page
      if isKnowledge && knowledgeId
        li
          strong Knowledge:
          |  
          a(href=`/chat4/viewknowledge/${knowledgeId}`, target="_blank", rel="noreferrer") View knowledge
      if isChat && conversationId
        li
          strong Chat:
          |  
          a(href=`/chat5/chat/${conversationId}`, target="_blank", rel="noreferrer") View chat
      if isASR && asrId
        li
          strong ASR job:
          |  
          a(href=`/asr/job/${asrId}`, target="_blank", rel="noreferrer") View job
      if isImagePrompt && imageId
        li
          strong Image job:
          |  
          a(href=`/image_gen/good?image=${imageId}`, target="_blank", rel="noreferrer") View job
      if group && group.dim
        li
          strong Dim:
          |  #{group.dim}
      if group && group.rerank && group.rerank.baseSimilarity !== undefined
        - const baseScore = Number.isFinite(group.rerank.baseSimilarity) ? group.rerank.baseSimilarity.toFixed(4) : group.rerank.baseSimilarity;
        li
          strong Base similarity:
          |  #{baseScore}
      if updatedAt
        li
          strong Updated:
          |  #{new Date(updatedAt).toLocaleString()}
    if group && group.chunks && group.chunks.length
      h6.small.mt-2.mb-1 Chunk samples
      table.table.table-sm.mb-2
        thead
          tr
            th text_index
            th chunk_index
            th tokens
            th Preview
        tbody
          each chunk in group.chunks
            tr
              td= chunk.textIndex
              td= chunk.chunkIndex
              td= `${chunk.startToken} - ${chunk.endToken}`
              td
                - const chunkText = chunk.previewText || ''
                | #{chunkText.length > 160 ? `${chunkText.slice(0, 160)}…` : chunkText || 'n/a'}
      if group.truncatedChunks
        p.text-muted.small.mb-0= `Showing ${group.chunks.length} of ${group.chunkCount} chunk${group.chunkCount === 1 ? '' : 's'}.`
    if opts && opts.allowDelete
      form.d-flex.flex-wrap.gap-2.mt-2(method="post", action="/admin/embedding-test/delete")
        input(type="hidden", name="collectionName", value=source.collectionName || '')
        input(type="hidden", name="documentId", value=source.documentId || '')
        input(type="hidden", name="contentType", value=source.contentType || '')
        input(type="hidden", name="parentCollection", value=source.parentCollection || '')
        input(type="hidden", name="parentId", value=source.parentId || '')
        input(type="hidden", name="mode", value=opts.mode || '')
        if opts.searchForm
          input(type="hidden", name="search_text", value=opts.searchForm.query || '')
          input(type="hidden", name="search_type", value=opts.searchForm.searchType || '')
          input(type="hidden", name="top_k", value=opts.searchForm.topK || '')
          input(type="hidden", name="start_date", value=opts.searchForm.startDate || '')
          input(type="hidden", name="end_date", value=opts.searchForm.endDate || '')
        button.btn.btn-outline-danger.btn-sm(type="submit") Delete embeddings

block content
  .row
    .col-xl-8
      h1.mb-3 Embedding Management
      p.text-muted.mb-4 Search stored embeddings, review recent writes, and remove entries that were added by mistake.

      if deleteFeedback
        .alert(class=deleteFeedback.status === 'success' ? 'alert-success' : 'alert-danger', role="alert")= deleteFeedback.message

      form.card.mb-4(method="post", action="/admin/embedding-test/search")
        .card-body
          h5.mb-3 Search embeddings
          p.text-muted.small.mb-3 Grouped by Source + Parent so you can delete all chunks for a document at once.
          .mb-3
            label.form-label(for="search_text") Query text
            textarea#search_text.form-control(name="search_text", rows="3", required, placeholder="Enter text to search stored embeddings")= searchForm && searchForm.query
          .mb-3
            label.form-label(for="search_type") Search type
            select#search_type.form-select(name="search_type")
              each option in searchTypes
                option(value=option.value, selected=searchForm && searchForm.searchType === option.value)= option.label
            small.form-text.text-muted Choose normal, high-quality, or combined (reranked) search.
          .row
            .col-md-6.mb-3
              label.form-label(for="start_date") Updated start date
              input#start_date.form-control(type="date", name="start_date", value=searchForm && searchForm.startDate ? searchForm.startDate : '')
              small.form-text.text-muted Inclusive; leave blank for no minimum.
            .col-md-6.mb-3
              label.form-label(for="end_date") Updated end date
              input#end_date.form-control(type="date", name="end_date", value=searchForm && searchForm.endDate ? searchForm.endDate : '')
              small.form-text.text-muted Inclusive; leave blank for no maximum.
          .mb-3
            label.form-label(for="top_k") Results to return
            input#top_k.form-control(type="number", name="top_k", min="1", max=searchLimits && searchLimits.maxTopK ? searchLimits.maxTopK : 50, value=searchForm && searchForm.topK !== undefined ? searchForm.topK : (searchLimits && searchLimits.defaultTopK ? searchLimits.defaultTopK : 10))
            small.form-text.text-muted= `Between 1 and ${(searchLimits && searchLimits.maxTopK) || 50} results`
          button.btn.btn-primary(type="submit") Search embeddings

      if searchError
        .alert.alert-danger(role="alert")= searchError
      if searchResult
        .card.mb-4
          .card-body
            h5.mb-3 Search results
            .d-flex.flex-wrap.gap-3.align-items-center.mb-3
              span.badge.text-bg-light.text-secondary= `${(searchResult.results && searchResult.results.length) || 0} match(es)`
              span.badge.text-bg-light.text-secondary Dim #{searchResult.dim || 'unknown'}
              if searchResult.model
                span.badge.text-bg-light.text-secondary= searchResult.model
              if searchResult.modeLabel
                span.badge.text-bg-info= searchResult.modeLabel
              else if searchResult.mode
                span.badge.text-bg-info= searchResult.mode
              if searchResult.apiBase
                span.badge.text-bg-light.text-secondary= searchResult.apiBase
              if searchResult.reranked
                span.badge.text-bg-warning.text-dark Reranked
              if searchForm && (searchForm.startDate || searchForm.endDate)
                span.badge.text-bg-light.text-secondary= `Updated ${searchForm.startDate || 'start'} -> ${searchForm.endDate || 'now'}`
            if searchGroups && searchGroups.length
              each group, idx in searchGroups
                +embeddingGroup(group, { index: idx, mode: searchResult.mode, modeLabel: searchResult.modeLabel, topK: searchResult.topK, allowDelete: true, searchForm: searchForm })
            else
              p.text-muted.mb-0 No matches found yet. Run a search above.
      else
        .card
          .card-body
            h6.mb-2 Search results
            p.text-muted.mb-0 Submit a query above to search stored embeddings.

      if recentEmbeddings
        h3.mt-5.mb-3= `Recent embeddings (last ${recentHours || 24}-hour window)`
        .row
          each modeKey in ['default', 'high_quality']
            - const recent = recentEmbeddings && recentEmbeddings[modeKey];
            .col-12
              .card.mb-3
                .card-body
                  .d-flex.justify-content-between.align-items-center.mb-2
                    h6.mb-0= recent ? (recent.label || modeKey) : modeKey
                    if recent
                      .d-flex.gap-2
                        span.badge.text-bg-light.text-secondary= `${recent.totalCount || 0} chunk(s)`
                        if recent.truncated
                          span.badge.text-bg-warning.text-dark Truncated
                  if recent && recent.error
                    .alert.alert-warning.mb-0(role="alert")= recent.error
                  else if recent && recent.groups && recent.groups.length
                    p.text-muted.small.mb-3= `Showing ${recent.groups.length} source group${recent.groups.length === 1 ? '' : 's'} updated since ${recent.since ? recent.since.toLocaleString ? recent.since.toLocaleString() : new Date(recent.since).toLocaleString() : 'start of window'}.`
                    each group, idx in recent.groups
                      +embeddingGroup(group, { index: idx, mode: modeKey, modeLabel: recent.label, allowDelete: true })
                  else
                    p.text-muted.mb-0 No embeddings stored in this window.
    .col-xl-4
      .card.mb-3
        .card-body
          h5.mb-2 API health
          p.mb-1
            strong Base:
            code.ms-1= apiBase
          if highQualityApiBase
            p.mb-1
              strong High-quality:
              code.ms-1= highQualityApiBase
          if health
            p.mb-2
              strong Status:
              if health.status && health.status.toLowerCase() === 'ok'
                span.text-success.ms-1= health.status
              else
                span.text-warning.ms-1= health.status || 'unknown'
            if health.model
              p.mb-1
                strong Model:
                span.ms-1= health.model
            if health.model_max_tokens
              p.mb-1
                strong model_max_tokens:
                span.ms-1= health.model_max_tokens
            p.mb-0.text-muted
              | cuda: #{health.cuda ? 'true' : 'false'}, on-demand GPU: #{health.use_on_demand_gpu ? 'true' : 'false'}
          else if healthError
            .alert.alert-warning.mb-0(role="alert")= healthError
          else
            p.text-muted.mb-0 No health data yet.

      details.card.mb-3(open=result || error || info)
        summary.p-3.mb-0.fw-semibold Manual embedding test
        .card-body
          if error
            .alert.alert-danger(role="alert")= error
          if info
            .alert.alert-info(role="alert")= info
          form.mb-3(method="post", action="/admin/embedding-test")
            .mb-3
              label.form-label(for="text") Text
              textarea#text.form-control(name="text", rows="5", required, placeholder="Enter text to embed")= form.text
              small.form-text.text-muted Use split mode below to send multiple texts at once.
            .mb-3
              label.form-label.d-block(for="split_mode") Split mode
              .d-flex.flex-wrap.align-items-center.gap-3
                .form-check.form-check-inline
                  input#split_single.form-check-input(type="radio", name="split_mode", value="single", checked=form.splitMode !== 'lines')
                  label.form-check-label(for="split_single") Single block
                .form-check.form-check-inline
                  input#split_lines.form-check-input(type="radio", name="split_mode", value="lines", checked=form.splitMode === 'lines')
                  label.form-check-label(for="split_lines") One text per line
              small.form-text.text-muted Max #{maxTexts} texts per request.
            .mb-3
              .form-check.form-switch
                input#auto_chunk.form-check-input(type="checkbox", name="auto_chunk", checked=form.autoChunk)
                label.form-check-label(for="auto_chunk") auto_chunk (let the API chunk automatically)
              small.form-text.text-muted Uncheck to send the raw text without auto chunking.
            .row
              .col-md-6.mb-3
                label.form-label(for="max_tokens_per_chunk") max_tokens_per_chunk
                input#max_tokens_per_chunk.form-control(type="number", name="max_tokens_per_chunk", min="1", step="1", value=form.maxTokensPerChunk === '' ? '' : form.maxTokensPerChunk)
                small.form-text.text-muted Leave blank to use the API default.
              .col-md-6.mb-3
                label.form-label(for="overlap_tokens") overlap_tokens
                input#overlap_tokens.form-control(type="number", name="overlap_tokens", min="0", step="1", value=form.overlapTokens === '' ? '' : form.overlapTokens)
                small.form-text.text-muted Default #{defaultOverlap}; leave blank to use the API default.
            button.btn.btn-outline-primary(type="submit") Generate embeddings
          if result
            .border.rounded-3.p-3
              h6.mb-2 Response
              .d-flex.flex-wrap.gap-2.align-items-center.mb-2
                span.badge.text-bg-success= result.model || 'unknown model'
                span.badge.text-bg-light.text-secondary Dim #{result.dim || 'N/A'}
                span.badge.text-bg-light.text-secondary= `${(result.vectors && result.vectors.length) || 0} vector(s)`
                span.badge.text-bg-light.text-secondary= `${(result.chunks && result.chunks.length) || 0} chunk(s)`
              if submittedTexts && submittedTexts.length
                h6.mt-2.mb-2 Sent texts
                ul.mb-3
                  each t, idx in submittedTexts
                    if idx < 3
                      li
                        span.fw-semibold= `#${idx + 1} `
                        | #{t.length > 200 ? `${t.slice(0, 200)}…` : t}
                  if submittedTexts.length > 3
                    li.text-muted= `+${submittedTexts.length - 3} more`
              if result.chunks && result.chunks.length
                h6.mt-3.mb-2 Chunk details
                table.table.table-sm
                  thead
                    tr
                      th #
                      th text_index
                      th chunk_index
                      th tokens
                      th length
                  tbody
                    each chunk, idx in result.chunks
                      tr
                        td= idx + 1
                        td= chunk.text_index
                        td= chunk.chunk_index
                        td= `${chunk.start_token} - ${chunk.end_token}`
                        td= chunk.end_token - chunk.start_token
              if result.vectors && result.vectors.length
                - const firstVector = Array.isArray(result.vectors[0]) ? result.vectors[0] : [];
                h6.mt-3.mb-1 First vector preview
                p.text-muted.mb-1= `Showing first ${Math.min(firstVector.length, 12)} values from chunk 0`
                code.d-block= JSON.stringify(firstVector.slice(0, 12))
              details.mt-3
                summary Raw response
                pre.small= JSON.stringify(result, null, 2)
          else
            p.text-muted.mb-0 Submit text above to see embeddings.
